{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI-Based Traffic Monitoring System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Packages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is a Python script that performs various image and video processing tasks using several libraries and packages. Here's a brief overview of what it does:\n",
    "\n",
    "1. **Importing Packages**: It starts by importing various Python libraries and packages, including:\n",
    "   - `cv2` for computer vision tasks.\n",
    "   - `ultralytics` for YOLO (You Only Look Once) object detection.\n",
    "   - `matplotlib.pyplot` and `seaborn` for data visualization.\n",
    "   - `pandas` and `numpy` for data manipulation.\n",
    "   - `os` for working with the operating system.\n",
    "   - `subprocess` for subprocess management.\n",
    "   - `tqdm` for creating progress bars.\n",
    "   - `IPython` and `IPython.display` for interactive display.\n",
    "   - `imutils` for basic image processing.\n",
    "   - `pytesseract` for text extraction from images.\n",
    "\n",
    "2. **Magic Command**: `%matplotlib inline` is a magic command used in Jupyter notebooks to display matplotlib plots inline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import IPython\n",
    "from IPython.display import Video, display\n",
    "\n",
    "import imutils\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieving and Displaying Video**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code performs the following tasks:\n",
    "\n",
    "1. **Video Input**: It prompts the user to enter the name of a video by using the `input` function and stores the input in the `videoName` variable. The code then constructs the full path to the video by appending the user-provided filename to the 'Videos/' directory.\n",
    "\n",
    "2. **Video Size**: It sets the `size` variable to 0.5, which is used to scale the video's dimensions. In this case, the video's height and width are reduced to half of their original values.\n",
    "\n",
    "3. **Display Video**: It uses the `display` function from the IPython library to display the video specified by the constructed `path` variable. The video is displayed with the adjusted height and width based on the `size` variable.\n",
    "\n",
    "This code snippet is designed to allow users to input the name of a video file and then display that video with size adjustments for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get path to video\n",
    "videoName = input(\"Enter Video Name: \")\n",
    "path = 'Videos/' + videoName\n",
    "\n",
    "#Altering video size\n",
    "size = 0.5 \n",
    "\n",
    "#Displaying the video \n",
    "display(Video(data = path, height = int(720 * size), width = int(1280 * size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading YOLOv8 Model and Displaying Model Class Names**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code snippet performs several tasks related to optical character recognition (OCR) and object detection using the YOLOv8 model:\n",
    "\n",
    "1. **Tesseract Configuration**: It sets the Tesseract OCR executable path using the `pytesseract.pytesseract.tesseract_cmd` attribute. This specifies the location of the Tesseract OCR binary on the local file system.\n",
    "\n",
    "2. **Loading YOLOv8 Model**: It loads the YOLOv8 object detection model using the `YOLO` class from the 'yolov8x.pt' model checkpoint file.\n",
    "\n",
    "3. **Getting Model Class Names**: It retrieves the class names used by the YOLOv8 model and stores them in the `dict_classes` variable.\n",
    "\n",
    "4. **Displaying Model Class Names**: It prints the model's class names to the console by iterating through the `dict_classes` dictionary.\n",
    "\n",
    "The code snippet combines OCR and object detection capabilities, configuring Tesseract for text extraction and loading the YOLOv8 model for object recognition. It also demonstrates how to access and display the model's class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "#Loading YOLOv8 Model\n",
    "model = YOLO('yolov8x.pt')\n",
    "\n",
    "#Getting Model Class Names\n",
    "dict_classes = model.model.names\n",
    "\n",
    "#Displaying Model Class Names\n",
    "print(\"Class Names: \")\n",
    "for name in dict_classes:\n",
    "    print(dict_classes[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Function to Resize Frame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code defines a function named `resizeFrame` that is used to resize an input image frame based on a scaling factor provided as the `scale` parameter. Here's a breakdown of what the code does:\n",
    "\n",
    "1. **Function Definition**: It defines a function named `resizeFrame` that takes two parameters: `frame` (the input image frame to be resized) and `scale` (the scaling factor expressed as a percentage).\n",
    "\n",
    "2. **Calculating New Dimensions**: It calculates the new dimensions (width and height) for the resized image using the provided scaling factor. The `width` and `height` are calculated as a percentage of the original dimensions of the input frame.\n",
    "\n",
    "3. **Resizing Image**: It resizes the input image frame using the calculated dimensions. The `cv2.resize` function from the OpenCV library is used for this purpose, with the `INTER_AREA` interpolation method.\n",
    "\n",
    "4. **Return Resized Image**: The function returns the resized image as the output.\n",
    "\n",
    "This code snippet provides a convenient function for resizing image frames, which can be useful in various computer vision and image processing applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which resizes the frame size depending on the scale_percent parameter passed\n",
    "def resizeFrame(frame, scale):\n",
    "    #Getting Dimensions\n",
    "    width = int(frame.shape[1] * scale / 100)   \n",
    "    height = int(frame.shape[0] * scale / 100)\n",
    "    dimensions = (width, height)\n",
    "\n",
    "    #Resizing Image\n",
    "    resized = cv2.resize(frame, dimensions, interpolation = cv2.INTER_AREA)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configurations (Scaling)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code snippet sets the `scale` variable to a value of 50. The `scale` variable represents a scaling percentage, indicating how much an image or frame should be resized. In this case, the value of 50 indicates that the frame should be scaled down to 50% of its original size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling percentage of original frame\n",
    "scale = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading Video with CV2 and Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code reads a video file using OpenCV, selects specific objects for detection (bicycle, car, motorcycle, airplane, bus, train, truck, boat), and performs various operations on the video frames. Here's a breakdown of what the code does:\n",
    "\n",
    "1. **Reading Video**: It opens a video file specified by the `path` variable using the `cv2.VideoCapture` function.\n",
    "\n",
    "2. **Object Selection**: It defines a list of class names and class labels for the objects to be detected. `classNames` contains numeric class IDs, and `classLabels` contains corresponding human-readable labels.\n",
    "\n",
    "3. **Dictionaries Initialization**: Two dictionaries, `vehiclesIn` and `vehiclesOut`, are created to keep track of the count of each class of objects entering and exiting the scene. The dictionaries are initialized with class IDs as keys, and the initial count is set to 0 for each class.\n",
    "\n",
    "4. **List for Frames**: An empty list `framesList` is created to store video frames.\n",
    "\n",
    "5. **Getting Video Information**: It retrieves information about the video, including frame height, width, and frames per second (fps). It also initializes variables for counting vehicles entering (`vehicleIn`) and exiting (`vehicleOut`) the scene. Additionally, there are variables related to checking and setting offsets.\n",
    "\n",
    "6. **Scaling Video**: If a scaling factor (`scale`) other than 100% is provided, it calculates new dimensions for the video based on the scaling factor. The `width` and `height` are adjusted accordingly.\n",
    "\n",
    "The code snippet sets up the video processing environment, defines object classes, and prepares data structures for tracking objects entering and exiting the scene in the video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Video\n",
    "video = cv2.VideoCapture(path)\n",
    "\n",
    "#Selecting Objects to be detected (bicycle, car, motorcycle, airplane, bus, train, truck, boat)\n",
    "classNames = [1, 2, 3, 4, 5, 6, 7, 8] \n",
    "classLabels = [\"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\"]\n",
    "\n",
    "#Create dictionaries with classNames as keys and 0 as the initial value of each\n",
    "vehiclesIn = dict.fromkeys(classNames, 0)\n",
    "vehiclesOut = dict.fromkeys(classNames, 0)\n",
    "\n",
    "#List to Store Frames\n",
    "framesList = []\n",
    "\n",
    "#Getting Video Information\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "vehicleIn = 0\n",
    "vehicleOut = 0\n",
    "checkOffset = int(2000 * scale/100) \n",
    "offset = int(8 * scale/100 )\n",
    "\n",
    "#Scaling Video\n",
    "if scale != 100:\n",
    "    width = int(width * scale / 100)\n",
    "    height = int(height * scale / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preparing Video Output**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code snippet sets up video-related parameters and creates an output video file using OpenCV. Here's an explanation of what this code does:\n",
    "\n",
    "1. **Setting Video Name, Path, and Type**: It defines variables for the video name (`videoName`), output path (`path`), a temporary output path (`tmp_output_path`), and the video codec to be used (`VIDEO_CODEC`). The video name is specified as \"Video13.mp4,\" and the `path` and `tmp_output_path` variables are created by appending prefixes \"rep_\" and \"tmp_\" to the video name, respectively. The `VIDEO_CODEC` variable is set to \"MP4V.\"\n",
    "\n",
    "2. **Set Video**: It creates an output video writer object (`outputVideo`) using the `cv2.VideoWriter` function. This object is used to write frames to an output video file.\n",
    "\n",
    "   - `videoName`: The name of the output video file.\n",
    "   - `cv2.VideoWriter_fourcc(*VIDEO_CODEC)`: It specifies the video codec to be used for encoding the output video. The `VIDEO_CODEC` variable is passed as an argument, and the `*` operator is used to unpack it.\n",
    "   - `10`: The frames per second (fps) for the output video. In this case, it is set to 10 fps.\n",
    "   - `(width, height)`: The width and height of the output video frames, which are taken from previously defined variables.\n",
    "\n",
    "This code prepares to create an output video file with the specified parameters, including the video name, codec, frame rate, and frame dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Video Name, Path and Type\n",
    "videoName = \"Video13.mp4\"\n",
    "path = \"rep_\" + videoName\n",
    "tmp_output_path = \"tmp_\" + path\n",
    "VIDEO_CODEC = \"MP4V\"\n",
    "\n",
    "#Set Video\n",
    "outputVideo = cv2.VideoWriter(videoName, cv2.VideoWriter_fourcc(*VIDEO_CODEC), 10, (width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extract Lower Triangle Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code defines a function named `extractLowerTriangle` that processes an input image to extract its lower triangular region. Here's a breakdown of what the code does:\n",
    "\n",
    "1. **Function Definition**: It defines a function called `extractLowerTriangle` that takes an image as input.\n",
    "\n",
    "2. **Mask Initialization**: It creates a binary mask of zeros with the same dimensions as the input image to isolate the desired region.\n",
    "\n",
    "3. **Polygon Definition**: It defines a set of points as a NumPy array to create a polygon representing the lower triangular region within the image.\n",
    "\n",
    "4. **Drawing the Polygon**: The code draws the specified polygon on the mask using a white color (255, 255, 255). The `-1` parameter fills the polygon, and `cv2.LINE_AA` specifies anti-aliased line drawing.\n",
    "\n",
    "5. **Bitwise AND Operation**: It performs a bitwise AND operation between the input image and the mask. This operation isolates the lower triangular region of the image.\n",
    "\n",
    "6. **Bounding Rectangle**: The code calculates the bounding rectangle (x, y, width, height) that encloses the non-zero region of the mask.\n",
    "\n",
    "7. **Cropping**: It crops the result image using the bounding rectangle coordinates to obtain the lower triangular region.\n",
    "\n",
    "8. **White Background Creation**: A white background image of the same size as the original image is created.\n",
    "\n",
    "9. **Inverting the Mask**: The mask is inverted, turning the isolated region into a white background and the rest into black.\n",
    "\n",
    "10. **Overlaying Images**: The cropped image is overlaid on top of the white background, creating the final result.\n",
    "\n",
    "11. **Return**: The function returns the processed image containing the lower triangular region.\n",
    "\n",
    "This code snippet provides a way to extract and isolate a specific region within an input image using masking and polygon manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts the lower triangular region of an input image.\n",
    "def extractLowerTriangle(image):\n",
    "    # Create a mask of zeros with the same dimensions as the input image.\n",
    "    mask = np.zeros(image.shape[0:2], dtype=np.uint8)\n",
    "    \n",
    "    # Define the coordinates of points to create a polygon (lower triangle) using NumPy arrays.\n",
    "    points = np.array([[\n",
    "        [int(image.shape[1] / 2), int(image.shape[0] / 4)],\n",
    "        [0, int(image.shape[0] / 2)],\n",
    "        [0, image.shape[0]],\n",
    "        [image.shape[1], image.shape[0]],\n",
    "        [image.shape[1], int(image.shape[0] / 2)]\n",
    "    ]])\n",
    "\n",
    "    # Draw the specified polygon on the mask with a white color (255, 255, 255).\n",
    "    # The -1 parameter fills the polygon, and cv2.LINE_AA specifies anti-aliased line drawing.\n",
    "    cv2.drawContours(mask, [points], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "    # Perform bitwise AND operation between the input image and the mask.\n",
    "    res = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Get the bounding rectangle (x, y, width, height) that encloses the non-zero region of the mask.\n",
    "    rect = cv2.boundingRect(points)\n",
    "    \n",
    "    # Crop the result image using the bounding rectangle coordinates.\n",
    "    cropped = res[rect[1]: rect[1] + rect[3], rect[0]: rect[0] + rect[2]]\n",
    "\n",
    "    # Create a white background image with the same size as the original image.\n",
    "    wbg = np.ones_like(image, np.uint8) * 255\n",
    "    \n",
    "    # Invert the mask and apply it to the white background to create the inverse region.\n",
    "    cv2.bitwise_not(wbg, wbg, mask=mask)\n",
    "    \n",
    "    # Overlay the cropped image on top of the white background.\n",
    "    dst = wbg + res\n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resize Image Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code defines a function named `resizeImage` that performs image resizing using the OpenCV library. Here's a breakdown of what the code does:\n",
    "\n",
    "1. **Function Definition**: It defines a function called `resizeImage` that takes an image (`img`) as input.\n",
    "\n",
    "2. **Image Resizing**: Inside the function, it resizes the input image using the `cv2.resize` function. The resizing is performed with the following parameters:\n",
    "   - `dsize=None`: The new size of the image is not explicitly specified, as it will be determined by the scaling factors.\n",
    "   - `fx=2` and `fy=2`: Both scaling factors (`fx` and `fy`) are set to 2, which effectively doubles the dimensions of the image in both the horizontal and vertical directions.\n",
    "   - `interpolation=cv2.INTER_AREA`: The interpolation method used for resizing is `INTER_AREA`, which is a method suitable for downsampling and helps preserve image quality.\n",
    "\n",
    "3. **Return Resized Image**: The function returns the resized image (`resized`) as the output.\n",
    "\n",
    "This code snippet provides a convenient function for resizing images, with options to control the scaling factors and the interpolation method used during resizing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function resizes an input image using OpenCV.\n",
    "\n",
    "def resizeImage(img):\n",
    "    # Resize the input image using the specified scaling factors (fx and fy).\n",
    "    # In this case, both scaling factors (fx and fy) are set to 2, doubling the image dimensions.\n",
    "    # The interpolation method used is INTER_AREA, which is suitable for downsampling.\n",
    "    resized = cv2.resize(img, dsize=None, fx=2, fy=2, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Return the resized image as the output.\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Add Text Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code defines a versatile function named `draw_text` that facilitates text drawing on an image using OpenCV. Here's a breakdown of what the code does:\n",
    "\n",
    "1. **Function Definition**: It defines a function called `draw_text` that takes several parameters to customize text appearance and positioning on an image.\n",
    "\n",
    "2. **Coordinate Extraction**: Inside the function, it extracts the x and y coordinates from the provided 'pos' tuple, which determines where the text will be drawn on the image.\n",
    "\n",
    "3. **Text Size Calculation**: It calculates the size of the text using OpenCV's `getTextSize` function, considering factors such as the text itself, font choice, font scale, and font thickness. The resulting dimensions are stored in the `text_size` variable.\n",
    "\n",
    "4. **Background Rectangle**: The code draws a filled rectangle as the background for the text. The background's color is specified by the `text_color_bg` parameter, and the `-1` parameter ensures that the rectangle is entirely filled.\n",
    "\n",
    "5. **Text Drawing**: The text is added on top of the filled rectangle using the `cv2.putText` function. The text's color is determined by the `text_color` parameter, and the placement ensures it appears just above the background rectangle.\n",
    "\n",
    "6. **Return Text Size**: The function returns the size of the drawn text as a tuple (`text_size`) for reference.\n",
    "\n",
    "This code snippet provides a flexible tool for overlaying text on images with options for text style, positioning, and background customization, making it useful in various image annotation and captioning applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function draws text on an image using OpenCV.\n",
    "\n",
    "def draw_text(img, text,\n",
    "              font=cv2.FONT_HERSHEY_PLAIN,\n",
    "              pos=(0, 0),\n",
    "              font_scale=3,\n",
    "              font_thickness=2,\n",
    "              text_color=(255, 255, 255),\n",
    "              text_color_bg=(0, 0, 0)\n",
    "              ):\n",
    "    # Extract the x and y coordinates from the provided 'pos' tuple.\n",
    "    x, y = pos\n",
    "    \n",
    "    # Calculate the size of the text using OpenCV's 'getTextSize' function.\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    text_w, text_h = text_size\n",
    "    \n",
    "    # Draw a filled rectangle as the background for the text.\n",
    "    cv2.rectangle(img, pos, (x + text_w, y + text_h), text_color_bg, -1)\n",
    "    \n",
    "    # Add the text on top of the filled rectangle.\n",
    "    cv2.putText(img, text, (x, y + text_h + font_scale - 1), font, font_scale, text_color, font_thickness)\n",
    "\n",
    "    # Return the size of the drawn text for reference.\n",
    "    return text_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Performing Vehicle Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code snippet processes video frames for vehicle detection and license plate recognition. Here's an overview of what the code accomplishes:\n",
    "\n",
    "1. **Initialization**: The code initializes several variables, including `counter` to control frame processing frequency, `textDoc` to store recognized license plates, and a loop for iterating through video frames.\n",
    "\n",
    "2. **Frame Processing**: For each video frame, it reads the frame, resizes it, and makes a copy for license plate processing. It also checks for predictions using a model and extracts bounding box information.\n",
    "\n",
    "3. **Vehicle Counting**: The code counts vehicles entering and exiting based on their positions in the frame and updates the `vehicleIn` and `vehicleOut` counters.\n",
    "\n",
    "4. **Drawing**: It draws bounding boxes around detected vehicles and displays vehicle class labels, speeds, and a transition line for counting.\n",
    "\n",
    "5. **License Plate Processing**: If conditions are met, it processes the detected vehicles to recognize license plates. This involves contour detection, filtering, and optical character recognition (OCR) using Tesseract. Recognized license plates are appended to `textDoc`.\n",
    "\n",
    "6. **Display and Output**: The code displays the current frame with vehicle annotations, saves processed frames to a list, and writes them to an output video file. It also saves recognized license plates to a text file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "counter = 1  # Frame processing counter\n",
    "textDoc = \"\"  # Store recognized license plates\n",
    "\n",
    "# Loop through each frame in the video\n",
    "for i in tqdm(range(int(video.get(cv2.CAP_PROP_FRAME_COUNT)))):\n",
    "\n",
    "    # Decrement the counter\n",
    "    counter -= 1\n",
    "\n",
    "    # Read a frame from the video\n",
    "    _, frame = video.read()\n",
    "\n",
    "    # Resize the frame\n",
    "    frame = resizeFrame(frame, scale)\n",
    "\n",
    "    # Create a copy of the current frame for license plate processing\n",
    "    numberPlateFrame = frame.copy()\n",
    "\n",
    "    # Perform predictions for vehicle detection\n",
    "    if counter == 0:\n",
    "        predictions = model.predict(frame, show=True)\n",
    "        counter = 5\n",
    "\n",
    "    # Retrieve bounding boxes, confidence scores, and class names\n",
    "    boxes = predictions[0].boxes.xyxy.cpu().numpy()\n",
    "    conf = predictions[0].boxes.conf.cpu().numpy()\n",
    "    classes = predictions[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "    # Store the above information in a DataFrame\n",
    "    informationFrame = pd.DataFrame(predictions[0].cpu().numpy().boxes.data, columns=['xmin', 'ymin', 'xmax', 'ymax', 'conf', 'class'])\n",
    "\n",
    "    # Translate numeric class labels to text\n",
    "    labels = [dict_classes[i] for i in classes]\n",
    "\n",
    "    # List to store detected vehicles\n",
    "    vehiclesDetected = []\n",
    "\n",
    "    # For each vehicle, draw a bounding box\n",
    "    for ix, row in enumerate(informationFrame.iterrows()):\n",
    "\n",
    "        # Get values from the current row\n",
    "        xmin, ymin, xmax, ymax, confidence, category = row[1].astype('int')\n",
    "\n",
    "        # Calculate the center of the bounding box\n",
    "        center_x, center_y = int(((xmax + xmin)) / 2), int((ymax + ymin) / 2)\n",
    "\n",
    "        offset = 0\n",
    "\n",
    "        # Check if the vehicle is near the transition line for counting\n",
    "        if (center_y < (380 + offset)) and (center_y > (380 - offset - 3)) and (counter == 5):\n",
    "            if (center_x >= 0) and (center_x <= checkOffset):\n",
    "                vehicleIn += 1\n",
    "            else:\n",
    "                vehicleOut += 1\n",
    "\n",
    "        # Draw a transition line for in/out vehicle counting\n",
    "        cv2.line(frame, (0, 380), (int(frame.shape[1]), 380), (255, 255, 0), 2)\n",
    "\n",
    "        # Draw the class name above the bounding box\n",
    "        if (labels[ix] in classLabels):\n",
    "            if (labels[ix] == \"car\"):\n",
    "                # Create an image with a red background for car class\n",
    "                image = 127 * np.ones((100, 200, 3), dtype=\"uint8\")\n",
    "                draw_text(frame, labels[ix] + ' - ' + str(np.round(conf[ix], 2)), font_scale=1, pos=(xmin, ymin - 25), text_color_bg=(255, 0, 0))\n",
    "                draw_text(frame, \"Speed: 30km/hr\", font_scale=1, pos=(xmin, ymin - 12), text_color_bg=(255, 0, 0))\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
    "                vehiclesDetected.append(cv2.resize(numberPlateFrame[ymin:ymax, xmin:xmax], (((xmax - xmin) * 2, (ymax - ymin) * 2)), interpolation=cv2.INTER_CUBIC))\n",
    "\n",
    "            elif (labels[ix] == \"bus\"):\n",
    "                draw_text(frame, labels[ix] + ' - ' + str(np.round(conf[ix], 2)), font_scale=1, pos=(xmin, ymin - 25), text_color_bg=(0, 255, 0))\n",
    "                draw_text(frame, \"Speed: 0km/hr\", font_scale=1, pos=(xmin, ymin - 12), text_color_bg=(0, 255, 0))\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                vehiclesDetected.append(cv2.resize(numberPlateFrame[ymin:ymax, xmin:xmax], (((xmax - xmin) * 2, (ymax - ymin) * 2)), interpolation=cv2.INTER_CUBIC))\n",
    "\n",
    "            elif (labels[ix] == \"truck\"):\n",
    "                draw_text(frame, labels[ix] + ' - ' + str(np.round(conf[ix], 2)), font_scale=1, pos=(xmin, ymin - 25), text_color_bg=(0, 0, 255))\n",
    "                draw_text(frame, \"Speed: 0km/hr\", font_scale=1, pos=(xmin, ymin - 12), text_color_bg=(0, 0, 255))\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (128, 128, 0), 2)\n",
    "                draw_text(frame, labels[ix] + ' - ' + str(np.round(conf[ix], 2)), font_scale=1, pos=(xmin, ymin - 25), text_color_bg=(128, 128, 0))\n",
    "                draw_text(frame, \"Speed: 0km/hr\", font_scale=1, pos=(xmin, ymin - 12), text_color_bg=(128, 128, 0))\n",
    "\n",
    "    # Draw the number of vehicles in/out\n",
    "    cv2.putText(img=frame, text=f'Vehicles In: {vehicleIn}',\n",
    "                org=(20, 40),\n",
    "                fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(0, 0, 0), thickness=2)\n",
    "\n",
    "    numberPlatesArea = []\n",
    "    tempCount = 1\n",
    "\n",
    "    for vehicle in vehiclesDetected:\n",
    "        numberPlatesArea.append(resizeImage(extractLowerTriangle(vehicle)))\n",
    "        tempCount += 1\n",
    "\n",
    "    if (counter == 5) and (len(numberPlatesArea) != 0):\n",
    "        for vehicleDetected in numberPlatesArea:\n",
    "            original_image = imutils.resize(vehicleDetected, width=500)\n",
    "\n",
    "            # Print the recognized text (license plate number)\n",
    "            cv2.imwrite(\"quadrantImage.jpg\", original_image)\n",
    "            gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "            gray_image = cv2.bilateralFilter(gray_image, 11, 17, 17)\n",
    "            edged_image = cv2.Canny(gray_image, 30, 200)\n",
    "            cv2.imwrite(\"cannyImage.jpg\", edged_image)\n",
    "            cv2.imshow(\"cannyIMG\", edged_image)\n",
    "            contours, new = cv2.findContours(edged_image.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            img1 = original_image.copy()\n",
    "            cv2.drawContours(img1, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "            contours = sorted(contours, key=cv2.contourArea, reverse=True)[:30]\n",
    "\n",
    "            # Stores the license plate contour\n",
    "            screenCnt = np.zeros(shape=(0, 0))\n",
    "            img2 = original_image.copy()\n",
    "\n",
    "            # Draw the top 30 contours\n",
    "            cv2.drawContours(img2, contours, -1, (0, 255, 0), 3)\n",
    "            cv2.imshow(\"Contours\", img2)\n",
    "            cv2.imwrite(\"contourImage.jpg\", img2)\n",
    "            count = 0\n",
    "            idx = 7\n",
    "\n",
    "            for c in contours:\n",
    "                # Approximate the license plate contour\n",
    "                contour_perimeter = cv2.arcLength(c, True)\n",
    "                approx = cv2.approxPolyDP(c, 0.020 * contour_perimeter, True)\n",
    "\n",
    "                # Look for contours with 4 corners\n",
    "                if len(approx) == 4:\n",
    "                    screenCnt = approx\n",
    "\n",
    "                    # Find the coordinates of the license plate contour\n",
    "                    x, y, w, h = cv2.boundingRect(c)\n",
    "                    new_img = original_image[y: y + h, x: x + w]\n",
    "\n",
    "                    # Store the new image\n",
    "                    cv2.imwrite('./' + str(idx) + '.png', new_img)\n",
    "                    idx += 1\n",
    "                    break\n",
    "\n",
    "            if screenCnt.size != 0:\n",
    "                # Draw the license plate contour on the original image\n",
    "                cv2.drawContours(original_image, [screenCnt], -1, (0, 255, 0), 3)\n",
    "                cv2.imshow(\"detected license plate\", original_image)\n",
    "                cv2.imwrite(\"licensePlate.jpg\", original_image)\n",
    "\n",
    "                # Filename of the cropped license plate image\n",
    "                cropped_License_Plate = './7.png'\n",
    "                cv2.imshow(\"cropped license plate\", cv2.imread(cropped_License_Plate))\n",
    "                cv2.imwrite(\"croppedLicensePlate.jpg\", cropped_License_Plate)\n",
    "                custom_config = r'--oem 3 --psm 6'  # OCR Engine Mode 3 and Page Segmentation Mode 6 for a single block of text\n",
    "\n",
    "                # Perform OCR on the cropped license plate image\n",
    "                text = pytesseract.image_to_string(cropped_License_Plate, config=custom_config, lang='eng')\n",
    "\n",
    "            if text != \"\":\n",
    "                print(\"License plate is:\", text)\n",
    "                textDoc += text + \"\\n\"\n",
    "\n",
    "    # Show the current frame\n",
    "    cv2.imshow(\"Current Frame\", frame)\n",
    "\n",
    "    # Save frames in a list\n",
    "    framesList.append(frame)\n",
    "\n",
    "    # Save transformed frames in an output video format\n",
    "    outputVideo.write(frame)\n",
    "\n",
    "# Write recognized license plates to a text file\n",
    "with open('numberplates.txt', 'w') as f:\n",
    "    f.write(textDoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating and Saving Video**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code snippet performs several tasks related to video processing and text file manipulation:\n",
    "\n",
    "1. **Releasing Video Output**: The code releases the video output using the `outputVideo.release()` function. This is typically done to free up system resources and ensure that the video is properly saved or closed.\n",
    "\n",
    "2. **Fixing Video Output Codec**: It checks if a file specified by the `path` variable exists. If it does, the code removes the file using `os.remove(path)`. This step is likely intended to ensure that there are no conflicts or issues with the video output file in the specified path.\n",
    "\n",
    "3. **Opening a Text File**: The code opens a text file named \"numberplates.txt\" in write mode using the `open()` function and assigns it to the `text_file` variable. This step prepares the file for writing text data.\n",
    "\n",
    "4. **Writing Text to File**: It writes the contents of the `textDoc` variable (presumably a string containing text data) to the opened text file using the `text_file.write(textDoc)` method. This allows the text data to be saved to the \"numberplates.txt\" file.\n",
    "\n",
    "5. **Closing the Text File**: Finally, the code closes the opened text file using `text_file.close()`. This step is important to ensure that any changes made to the file are saved and that system resources are released.\n",
    "\n",
    "Overall, this code snippet is involved in video processing and text file handling, where it releases video output, manages video output file conflicts, and writes text data to a specified text file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Releasing the video    \n",
    "outputVideo.release()\n",
    "\n",
    "# Fixing video output codec to run in the notebook\\browser\n",
    "if os.path.exists(path):\n",
    "    os.remove(path)\n",
    "\n",
    "#open text file\n",
    "text_file = open(\"numberplates.txt\", \"w\")\n",
    " \n",
    "#write string to file\n",
    "text_file.write(textDoc)\n",
    " \n",
    "#close file\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AITMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
